---
title: "Variance partitioning script"
author: "David S, Mason"
date: "5/6/2021"
output:
  pdf_document: default
  html_document: default
---
This is a script for conducting variance partitioning on understory vegetation data collected at 59 sites at Noxumbee National Wildlife Refuge and Tombigbee National Forest during two separate sampling periods. The environmental (explanatory) matrix includes overstory characteristics, soil analyses, and geospatially derived data, among other variables. UTM coordinates are also included (irregular, non-gridded design), so the analyses below includes a section deriving spatial descriptors for use in the variance partitioning. 

## Load packages
```{r,results='hide', message = FALSE}
library(tidyverse)
library(vegan)
library(ade4)
library(adespatial)
library(spdep)
library(betapart)
library(spdep)
library(corrplot)
library(SoDA) 
library(rgdal)
```
## Bring in the data
```{r}
spec <- read.csv("data/species.csv") # Species 
env <- read.csv("data/env_coords.csv") # Environmental
```

## Selecting species to use in the analyses

First, I use a package develoepd by Kevin McGarigal that identifies common and rare species. Then, I remove those species to generate a reduced species matrix. I will conduct analyses on both datasets.
```{r,fig.show='hide'}
source("code/biostats.r") # attach the code from biostats

occur <- foa.plots(spec)
rare <- which(occur[,2]<5)
common <- which(occur[,2]>95)

red_spec <- spec[,-c(rare,common)]
```

## Transforming the species data 
```{r}
spe.hel <- decostand(spec, "hellinger") 
red.spe.hel <- decostand(red_spec, "hellinger")
```
## Preparing environmental data 

The species data is ready for analysis, but I need to check the environmental data for collinearity. I will begin by removing some redunant variables from the matrix. Date is removed in favor of sampling period, numerical texture proportions are removed in favor of the categorical descriptor. Also, site is dropped because this is not an explanatory variable and spatial descriptors are dropped because these will be dealt with separately. Next, I need to separate the numerical variables from categorical variables for correlation analtses. I conclude this stage by converting disturbance intensity into an ordinal factor.
```{r}
# Drop site, date, spatial descriptors and texture proportions
red.env <- env[,-c(1:4,16,17,18)] 

# Separate the numerical data
env.numeric <- select(red.env, -PERIOD, -TEXTURE, -OWNERSHIP, -DISTURB, -INTENSITY)

# Separate the categorical and ordinal data
env.factors <- select(red.env, PERIOD, TEXTURE, OWNERSHIP, DISTURB, INTENSITY)

# Convert intensity into ordinal 
env.factors$INTENSITY <- factor(red.env$INTENSITY, order = TRUE, levels = c("NONE","LOW", "MED", "HIGH"))
```
### Checking for collinearity 

## Numeric variables

First, I scale all numerical variables and calculate correlations between all pairs. Then, I select all correlations above 0.7 and create a list of variables to be dropped from the dataset. 
```{r}
# Scale the data
red.env.cont.corr <- as.data.frame(scale(env.numeric)) %>% 
								 		cor(method = c("kendall"))

# Create a dataframe
red.env.cont.corr.df <-  as.data.frame(as.table(red.env.cont.corr))

# Filter for values above 0.7
red.env.cont.corr.filt <- red.env.cont.corr.df %>%  
															arrange(desc(Freq)) %>% 
															filter(Freq>0.7)

# Visualize the correlations
corrplot(red.env.cont.corr, tl.cex = 0.5)

# Create a vector of variables to drop
numeric.drop <- c("Morus.rubra", "Cercis.canadensis", "Ilex.decidua",
														 "S", "Asimina.triloba", "Carya.pallida")
```
## Disturbance type and numeric variables

Moving to the categorical variables, I separate disturbance into one vector and create a matrix of all the numeric variables. Then, I calculate a pseudo-r value and look for correlations above 0.7 (there are none).
```{r}
# Correlations among categorical and continuous variables

# DIST
red.env.factor.corr <- red.env %>% 
							select(-PERIOD, -TEXTURE, -OWNERSHIP, -INTENSITY) %>% 
							select(DISTURB, everything())

DIST <- red.env.factor.corr[,1]
red.env.factor.corr <- red.env.factor.corr[,-1]


rsq <- vector()
pseudo.r <- vector()
for(i in 1:84){
	mod <- lm(formula = red.env.factor.corr[,i] ~ DIST, 
					data = red.env.factor.corr)
	rsq <- summary(mod)$r.squared
	pseudo.r[i] <- sqrt(rsq)
}

pseudo.r <- as.data.frame(as.table(pseudo.r)) 
pseudo.r$Var1 <- as.vector(dimnames(red.env.factor.corr)[[2]]) 
```
## Sampling period

# Soil sodium (mg) is highly correlated (>0.7) with sampling period. 
```{r}
red.env.factor.corr <- red.env %>% 
	select(-DISTURB, -TEXTURE, -OWNERSHIP, -INTENSITY) %>% 
	select(PERIOD, everything())

PERIOD <- red.env.factor.corr[,1]
red.env.factor.corr <- red.env.factor.corr[,-1]
rsq <- vector()
pseudo.r <- vector()
for(i in 1:84){
	mod <- lm(formula = red.env.factor.corr[,i] ~ PERIOD, 
					data = red.env.factor.corr)
	rsq <-  summary(mod)$r.squared
	pseudo.r[i] <- sqrt(rsq)
}

pseudo.r <- as.data.frame(as.table(pseudo.r)) 
pseudo.r$Var1 <- as.vector(dimnames(red.env.factor.corr)[[2]]) 
```
## Soil texture and numeric variables

# Quercus pagoda importance value is highly correlated (>0.7) with soil texture
```{r}
red.env.factor.corr <- red.env %>% 
	select(-DISTURB, -TEXTURE, -OWNERSHIP, -INTENSITY) %>% 
	select(PERIOD, everything())

PERIOD <- red.env.factor.corr[,1]
red.env.factor.corr <- red.env.factor.corr[,-1]
rsq <- vector()
pseudo.r <- vector()
for(i in 1:84){
	mod <- lm(formula = red.env.factor.corr[,i] ~ PERIOD, 
					data = red.env.factor.corr)
	rsq <-  summary(mod)$r.squared
	pseudo.r[i] <- sqrt(rsq)
}

pseudo.r <- as.data.frame(as.table(pseudo.r)) 
pseudo.r$Var1 <- as.vector(dimnames(red.env.factor.corr)[[2]]) 
```
## Land onwership and numeric variables

# Distance (m) to highly developed land (DEVHI) is highly correlated (>0.7) with land ownership
```{r}
# OWNERSHIP
red.env.factor.corr <- red.env %>% 
	select(-PERIOD, -DISTURB, -TEXTURE, -INTENSITY) %>% 
	select(OWNERSHIP, everything())

OWNERSHIP <- red.env.factor.corr[,1]
red.env.factor.corr <- red.env.factor.corr[,-1]
rsq <- vector()
pseudo.r <- vector()
for(i in 1:84){
	mod <- lm(formula = red.env.factor.corr[,i] ~ OWNERSHIP, 
					data = red.env.factor.corr)
	rsq <-  summary(mod)$r.squared
	pseudo.r[i] <- sqrt(rsq)
}

pseudo.r <- as.data.frame(as.table(pseudo.r)) 
pseudo.r$Var1 <- as.vector(dimnames(red.env.factor.corr)[[2]]) 
```
## Disturbance intensity and numeric variables

# No numeric variables are highly correlated (>0.7) with land ownership
```{r}
red.env.factor.corr <- red.env %>% 
	select(-PERIOD, -DISTURB, -TEXTURE, -OWNERSHIP) %>% 
	select(INTENSITY, everything())

INTENSITY <- red.env.factor.corr[,1]
red.env.factor.corr <- red.env.factor.corr[,-1]
rsq <- vector()
pseudo.r <- vector()
for(i in 1:84){
	mod <- lm(formula = red.env.factor.corr[,i] ~ INTENSITY, 
					data = red.env.factor.corr)
	rsq <-  summary(mod)$r.squared
	pseudo.r[i] <- sqrt(rsq)
}

pseudo.r <- as.data.frame(as.table(pseudo.r)) 
pseudo.r$Var1 <- as.vector(dimnames(red.env.factor.corr)[[2]]) # nothing
```
## Creating the final environmental matrix

With these results, I can avoid collinearity by dropping highly correlated (>0.7) values. I create a vector of collinear categorical variables and combine this with the vector of collinear numeric variables. I need to use '%!in%' to pull anything in this collinear vector out of the environmental matrix. However, this function filters FOR whatever is in the vector. I need to pull everthing NOT in the vector, so I write a function for to do the opposite.
```{r}
# List of species correlated with categorical variables
categorical.drop <- c("soilNA", "Quercus.pagoda", "DEVHI")

# Combined list of correlated variables to drop
drop.list <- c(numeric.drop, categorical.drop)
# Drop the correlated variables
'%!in%' <- function(x,y){ 
	!('%in%'(x,y)) # make a function to do the opposite of %in%
}

# Bring the data back together
env.temp <- cbind(env.factors, scale(env.numeric))

# Drop the collinear variables
env.final <- env.temp[which(names(env.temp) %!in% drop.list)]	
```
## Selecting the variables from the environmental (explanatory) matrix to use for variance partitioning

Now that I have dropped the collinear variables, I can move forward with variable selection. At this point, I am running parallel analyses on both the full and reduced species matrix to see which is best explained by the data. First, I create an RDA object using the full final environmental matrix and the hellinger transformed species matrix. Then, I run this RDA object through a stepwise variable selection function. I am using forward selection, which starts by identifying the most explanatory (highest R2) significant variable and iteratively adding the next most explanatory variable remaining until the variables are no longer significant. 

The analysis using the reduced species matrix has more explanatory power than the analysis using the full matrix, so I will use the reduced species matrix moving forward.
```{r,message = FALSE,results = "hide"}
# Full species matrix and environmental variables = 13% explained
spe.rda <- rda(spe.hel ~ ., env.final)
full.step.forward <- ordiR2step(rda(spe.hel ~ 1, data=env.final), 
scope=formula(spe.rda), R2scope = F, direction="forward", pstep=1000)

# Reduced species matrix and environmental variables = 16% explained
red.spe.rda <- rda(red.spe.hel ~ ., env.final)
red.step.forward <- ordiR2step(rda(red.spe.hel ~ 1, data=env.final), 
scope=formula(red.spe.rda), R2scope = F, direction="forward", pstep=1000)
```
## Creating the spatial descriptor variables

In this next step, I am deriving and selecting spatial descriptors from the UTM coordinates of the site locations with an approach adapted from p. 326 of Brocard et al. (2018). First, I extract the spatial descriptors (UTM coordinates) from the environmental matrix. I give the columns false names (longitude and latitude) to match the input of geoXY(), which converts the coordinates into Euclidean distances. Then, I search for a linear pattern and detrend the data. At step 1, I begin the actual analysis by constructing a matrix of Euclidean distances among sites. Next, I truncate this matrix, only retaining distances among close neighbours. Then, I run a PCoA on the truncated matrix and retain significant eigenvectors that model positive spatial autocorrelation. Finally, I write these two? eigenvectors to a new vector for later use as spatial descriptors alongside environmental variables in variance partitioning. 

Outstanding questions: 
do I satisfy any minimum distance requirements (p.316)?
can I use geoXY on UTM coordinates?
```{r}
spatial.tmp <- as.data.frame(env[,2:3]) # extract spatial variables for later analysis
spatial.tmp <- rename(spatial.tmp, longitude = east_x, latitude = north_y)
spatial <- geoXY(spatial.tmp$longitude, spatial.tmp$latitude)

# Is there a linear trend in the mite data?
anova(rda(red.spe.hel, spatial)) # Result: significant trend
# Computation of linearly detrended mite data
red.spe.hel.det <- resid(lm(as.matrix(red.spe.hel) ~ ., data = as.data.frame(spatial)))

## Step 1. Construct the matrix of dbMEM variables
dbmem.tmp <- dbmem(spatial, silent = FALSE)
dbmem <- as.data.frame(dbmem.tmp)

# Truncation distance used above:
thr <- give.thresh(dist(spatial))

# Display and count the eigenvalues
attributes(dbmem.tmp)$values 
length(attributes(dbmem.tmp)$values) # 18 eigenvalues

## Step 2. Run the global dbMEM analysis on the detrended
## Hellinger-transformed reduced species data
dbmem.rda <- rda(red.spe.hel.det ~., dbmem)
anova(dbmem.rda) # model is significant


## Step 3. Since the R-square is significant, compute the adjusted
## R2 and run a forward selection of the dbmem variables 
R2a <- RsquareAdj(dbmem.rda)$adj.r.squared
dbmem.fwd <- forward.sel(red.spe.hel, as.matrix(dbmem),
												 adjR2thresh = R2a)

nb.sig.dbmem <- nrow(dbmem.fwd) # 3 signif. dbMEM

# Identity of the significant dbMEM in increasing order
dbmem.sign <- sort(dbmem.fwd[ ,2])

# Write the significant dbMEM to a new object 
dbmem.red <- dbmem[ ,c(dbmem.sign)]
```
## Visualizing the spatial descriptors

We already have the spatial descriptors written to an object to be used for variance partitioning. However, I would like to take a detour to visualize those descriptors. I use an approach derived from p.321 of Brocard et al (2019). 

Outstanding questions: why do we run the dbmem analyses twice for the visualization?
```{r}
## Step 1. Construct the matrix of dbMEM variables
dbmem.viz.tmp <- dbmem(spatial, silent = FALSE)
dbmem.viz <- as.data.frame(dbmem.tmp)

# Truncation distance used above:
thr <- give.thresh(dist(spatial))

# Display and count the eigenvalues
attributes(dbmem.viz.tmp)$values 
length(attributes(dbmem.viz.tmp)$values) 

## Step 2. Run the global dbMEM analysis on the detrended
## Hellinger-transformed reduced species data
dbmem.viz.rda <- rda(red.spe.hel ~., dbmem.viz)
anova(dbmem.viz.rda) # model is significant


## Step 3. Since the R-square is significant, compute the adjusted
## R2 and run a forward selection of the dbmem variables 
R2a.viz <- RsquareAdj(dbmem.viz.rda)$adj.r.squared
dbmem.viz.fwd <- forward.sel(red.spe.hel, as.matrix(dbmem.viz),
												 adjR2thresh = R2a.viz)

nb.sig.dbmem.viz <- nrow(dbmem.viz.fwd) 

# Identity of the significant dbMEM in increasing order
dbmem.viz.sign <- sort(dbmem.viz.fwd[ ,2])

# Write the significant dbMEM to a new object 
dbmem.viz.red <- dbmem.viz[ ,c(dbmem.viz.sign)]

## Step 4. New dbMEM analysis with 8 significant dbMEM variables ## Adjusted R-square after forward selection: R2adj = 0.2418
dbmem.viz.rda2 <- rda(red.spe.hel ~ ., data = dbmem.viz.red) 
fwd.viz.R2a <- RsquareAdj(dbmem.viz.rda2)$adj.r.squared
anova(dbmem.viz.rda2)

axes.test <- anova(dbmem.viz.rda2, by = "axis")

## Step 5. Plot the significant canonical axes
dbmem.viz.rda2.axes <- 
	scores(dbmem.viz.rda2, 
				 choices = c(1:nb.sig.dbmem.viz), 
				 display = "lc", 
				 scaling = 1) 

par(mfrow = c(1,nb.ax))
for(i in 1:nb.ax){
sr.value(spatial, mite.rda2.axes[ ,i],
sub = paste("RDA",i), csub = 2)

```
## Conducting variance partitioning

Now that we have the spatial descriptors and forward selected variables, we are ready to proceed with variance partitioning. First, we need to assign out variances to broad groups.
```{r}
spatiotemporal <- cbind(dbmem.red, env$PERIOD)
landscape <- select(env, OWNERSHIP, WATER.150, DECID, DEVOP, CROP, GRASS)
overstory <- select(env, CANOPY, Pinus.taeda, Quercus.alba)
soil.ground <- select(env, TEXTURE, MG, PH, ROCK)

red.spe.part <- varpart(red.spe.hel, spatiotemporal, landscape,
												overstory, soil.ground)

dev.off()
plot(red.spe.part, digits = 2, Xnames = c('Space & time', 'Landscape', 
		 'Overstory', 'Soil & ground'), id.size = 0.75, bg = 2:5)
```
## Test significance od fractions

Finally, we need to test the significance of these fractions by running  anova on RDAs of each fraction, including the whole thing. 

Outstanding question: do we need to run this on every single possible combo?
```{r}
env.final.xy <- cbind(env.final, dbmem.red)

rda.all <- rda(red.spe.hel ~MEM2+MEM4+MEM5+MEM15+PERIOD+
							 	OWNERSHIP+WATER.150+DECID+DEVOP+CROP+GRASS+
							 	CANOPY+Pinus.taeda+Quercus.alba+TEXTURE+MG+
							 	PH+ROCK, data = env.final.xy)
anova(rda.all)

rda.soil.ground <- rda(red.spe.hel ~ TEXTURE + 
											 	MG + PH + ROCK, data = env.final.xy)
anova(rda.soil.ground)

rda.overstory <- rda(red.spe.hel ~ CANOPY + Quercus.alba + 
					 					Pinus.taeda, data = env.final.xy)
anova(rda.overstory)

rda.landscape <- rda(red.spe.hel ~ DECID + DEVOP + CROP + 
								WATER.150 + GRASS + OWNERSHIP, data = env.final.xy)
anova(rda.landscape)

rda.space.time <- rda(red.spe.hel ~ PERIOD + MEM2 + MEM4 +
												MEM5 + MEM15, data = env.final.xy)
anova(rda.space.time)
```
